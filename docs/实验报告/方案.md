# 异构多活分布式数据库同步系统设计方案 (终极版)

## 1. 系统总体架构 (Architecture Design)

本系统采用 **“双主多活（Multi-Master） + 中央汇聚（Central Hub）”** 的星型拓扑架构。旨在解决跨校区网络延迟问题，实现就近访问、实时容灾及全局数据分析。

### 1.1 节点角色定义

- **节点 A（本部校区 - Edge North）**
    - **数据库类型：** **MariaDB**
    - **角色：** 读写主库 (Master A)
    - **职责：** 负责本部用户的实时交易（OLTP）。拥有数据的本地归属权。
    - **ID配置：** 雪花算法 `WorkerID = 1`
- **节点 B（南校区 - Edge South）**
    - **数据库类型：** **PostgreSQL**
    - **角色：** 读写主库 (Master B)
    - **职责：** 负责南校区用户的实时交易（OLTP）。拥有数据的本地归属权。
    - **ID配置：** 雪花算法 `WorkerID = 2`
- **节点 C（云端/总库 - Central Hub）**
    - **数据库类型：** **MySQL**
    - **角色：** 数据仓库 / 协调中心 (Warehouse/Coordinator)
    - **职责：**
        1. **数据汇聚：** 实时同步节点 A 和 B 的所有数据，作为全量备份。
        2. **分析报表：** 承载管理员的复杂查询和图形化报表分析（OLAP），避免拖慢业务主库。
        3. **同步中枢：** 部署 **“同步核心服务 (Sync Core)”**，这是系统的“大脑”，负责轮询日志、维护向量时钟逻辑、判定冲突以及**自动修复异常数据**。

------

## 2. 核心技术方案 (Core Technologies)

### 2.1 全局唯一 ID 生成：雪花算法 (Snowflake Algorithm)

为了彻底解决双主架构下的主键冲突问题，并保证系统未来的可扩展性（如增加新校区），放弃传统的数据库自增 ID。

- **原理：** 应用层生成 64 位 Long 类型整数（`1位符号 + 41位时间戳 + 10位机器ID + 12位序列号`）。
- **实施：**
    - 本部校区应用服务配置 `WorkerID = 1`，生成的 ID 如 `1845...001...`。
    - 南校区应用服务配置 `WorkerID = 2`，生成的 ID 如 `1845...002...`。
- **优势：** 保证了 ID 全局唯一、趋势递增（利于索引性能），且无需查询数据库即可生成。

### 2.2 数据一致性与冲突判定：应用层向量时钟 (Application-Layer Vector Clocks)

为了在物理时间不可靠的分布式环境中精准判定“同步”还是“冲突”，引入逻辑时钟，且**逻辑完全由后端代码控制**，以降低数据库负载并提高系统移植性。

- **结构：** 在每个业务表中增加字段 `v_clock` (类型为 JSON/Text)。
- **格式：** `{"N": counter, "S": counter}` (N代表本部，S代表南校)。
- **初始值：** `{"N": 0, "S": 0}`
- **代码层维护逻辑：**
    - 当 Java/Python 后端接收到本部用户的写请求时，先读取旧时钟，解析 JSON，将 `N` 值 `+1`，再写入数据库。
    - **注意：** 数据库仅作为存储介质，不参与时钟计算。

------

## 3. 数据库详细设计 (Schema Design)

为了支持异构同步，三个数据库（MariaDB, PostgreSQL, MySQL）需保持业务表结构一致，并增加同步辅助设施。

### 3.1 业务表结构示例 (Product 表)

| **字段名**  | **类型**  | **说明**                            |
| ----------- | --------- | ----------------------------------- |
| **id**      | BIGINT    | **主键** (由雪花算法生成，非自增)   |
| name        | VARCHAR   | 商品名称                            |
| price       | DECIMAL   | 价格                                |
| **v_clock** | TEXT/JSON | **向量时钟**，例：`{"N":1, "S":0}`  |
| update_time | DATETIME  | 最后修改物理时间 (用于辅助修补逻辑) |

### 3.2 同步日志表 (Sync_Log)

每个数据库中都建立此表，用于记录数据变更的“快照”。

| **字段名**   | **类型**  | **说明**                                |
| ------------ | --------- | --------------------------------------- |
| log_id       | BIGINT    | 自增日志ID                              |
| table_name   | VARCHAR   | 变更的表名 (如 "Product")               |
| data_id      | BIGINT    | 变更数据的业务ID                        |
| operation    | VARCHAR   | 操作类型 (INSERT/UPDATE/DELETE)         |
| **new_data** | TEXT/JSON | 变更后的完整数据行 (包含当下的 v_clock) |
| status       | INT       | 状态 (0:未同步, 1:已同步)               |

### 3.3 触发器设计 (Trigger) - 仅做记录

在 MariaDB 和 PostgreSQL 中编写 **“哑触发器” (Dumb Triggers)**。

- **逻辑：** 它们**不进行任何逻辑判断或计算**。当业务表发生变化时，无脑将 `NEW` 这一行数据转为 JSON 存入 `Sync_Log`。
- **目的：** 确保无论数据是如何修改的（App修改或Navicat修改），变更事件都能被捕获，绝不漏单。

------

## 4. 同步与冲突解决流程 (Workflow)

同步核心服务 (**Sync Core**) 部署在云端，运行轮询/监听任务，处理以下三种场景。

### 场景 A：正常同步 (Synchronization)

**假设：** 本部校区用户通过网页修改商品 A 的价格。

1. **应用层操作：** 后端代码读取商品 A，计算向量时钟 `{"N":0...} -> {"N":1...}`，执行 SQL 更新。
2. **日志捕获：** MariaDB 触发器将新数据（含新时钟）写入 `Sync_Log`。
3. **中枢分发：** Sync Core 读到日志，发现 `v_clock` 正常递增。
4. **判定：** 对比南校区当前数据，确认 `Remote > Local`。
5. **执行：** 将数据同步至南校区 PostgreSQL。

### 场景 B：并发冲突 (Conflict)

**假设：** 本部和南校区几乎同时修改商品 A。

1. **并发修改：**
    - 本部 App 改为 `{"N":1, "S":0}`。
    - 南校 App 改为 `{"N":0, "S":1}`。
2. **中枢检测：** Sync Core 抓取到两条日志。
3. **向量比对：** 发现 `[1,0]` 和 `[0,1]` 互不包含。
4. **冲突处理：** 停止同步，触发邮件报警，记录到 `Conflict_Table` 等待人工介入。

### 场景 C：外部变更与智能修补 (External Modification & Smart Fix)

**假设：** 运维人员通过 **Navicat** 直接在 MariaDB (本部) 修改了价格，**未更新 v_clock**。此时数据库中数据为 `Price=200`, `v_clock={"N":0, "S":0}`。

1. **日志捕获：** 触发器依然工作，将这条“异常数据”写入 `Sync_Log`。
2. **中枢检测 (Anomaly Detection)：**
    - Sync Core 读取日志，发现数据内容变了（Price 变了）。
    - **关键检查：** Sync Core 发现 `v_clock` 竟然还是 `{"N":0, "S":0}`（没有递增）。
    - **判定：** “检测到非标准渠道的数据变更（External Modification）”。
3. **智能修补 (Smart Fix)：**
    - Sync Core 主动在内存中执行修正逻辑：`New_Clock = {"N": 0+1, "S": 0} = {"N":1, "S":0}`。
    - **回写源库：** Sync Core 立即发起一个 UPDATE 请求给 MariaDB，把正确的 `v_clock` 补填回去，修正源头数据的一致性。
4. **继续同步：** 使用修正后的时钟 `{"N":1, "S":0}` 继续向南校区同步，仿佛这是一次正常的 App 操作。

------

## 5. 方案亮点总结 (Highlights)

1. 架构先进性 (Edge + Cloud)：

    本部和南校区作为“边缘节点”保证了极低的用户延迟和高可用性；云端 MySQL 作为“数据湖”和“计算中心”，实现了完美的读写分离与 OLTP/OLAP 分离。

2. 全栈异构融合 (Full-Stack Heterogeneity)：

    通过应用层 DAO 封装和中间件同步模式，成功打通了 MariaDB、PostgreSQL 和 MySQL 三种不同数据库，体现了极强的系统兼容性。

3. 工业级健壮性设计 (Robustness with Smart Fix)：

    针对数据库运维中常见的“绕过系统直接修改数据”的风险，设计了**“智能修补策略”**。Sync Core 具备自我修复能力，能自动识别时钟未更新的异常变更并进行校正，确保了系统在非标准操作下依然保持数据一致性。这是一般课程设计中罕见的高级容错特性。

4. 严谨的一致性模型 (App-Layer Vector Clocks)：

    将向量时钟逻辑置于应用层，既避免了复杂的数据库存储过程维护，又通过代码逻辑实现了对并发冲突的精准识别。配合雪花算法，构建了一套无中心、可扩展、高可用的分布式数据治理闭环。